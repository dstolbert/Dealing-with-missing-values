{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useducation'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "education_df = pd.read_sql_query('select * from useducation',con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>471564.0</td>\n",
       "      <td>196386.0</td>\n",
       "      <td>676174.0</td>\n",
       "      <td>208.327876</td>\n",
       "      <td>252.187522</td>\n",
       "      <td>207.963517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>79117.0</td>\n",
       "      <td>30847.0</td>\n",
       "      <td>112335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.859712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>437127.0</td>\n",
       "      <td>175210.0</td>\n",
       "      <td>614881.0</td>\n",
       "      <td>215.253932</td>\n",
       "      <td>265.366278</td>\n",
       "      <td>206.212716</td>\n",
       "      <td>262.169895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>281338.0</td>\n",
       "      <td>123113.0</td>\n",
       "      <td>405259.0</td>\n",
       "      <td>210.206028</td>\n",
       "      <td>256.312090</td>\n",
       "      <td>208.634458</td>\n",
       "      <td>264.619665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>3286034.0</td>\n",
       "      <td>1372011.0</td>\n",
       "      <td>4717112.0</td>\n",
       "      <td>208.398961</td>\n",
       "      <td>260.892247</td>\n",
       "      <td>196.764414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "0  ...     57948.0     58025.0      41167.0      471564.0       196386.0   \n",
       "1  ...      9748.0      8789.0       6714.0       79117.0        30847.0   \n",
       "2  ...     55433.0     49081.0      37410.0      437127.0       175210.0   \n",
       "3  ...     34632.0     36011.0      27651.0      281338.0       123113.0   \n",
       "4  ...    418418.0    363296.0     270675.0     3286034.0      1372011.0   \n",
       "\n",
       "   GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "0      676174.0        208.327876        252.187522           207.963517   \n",
       "1      112335.0               NaN               NaN                  NaN   \n",
       "2      614881.0        215.253932        265.366278           206.212716   \n",
       "3      405259.0        210.206028        256.312090           208.634458   \n",
       "4     4717112.0        208.398961        260.892247           196.764414   \n",
       "\n",
       "   AVG_READING_8_SCORE  \n",
       "0                  NaN  \n",
       "1           258.859712  \n",
       "2           262.169895  \n",
       "3           264.619665  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Determine all the variable types and find the fraction of the missing values for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 25 columns):\n",
      "PRIMARY_KEY                     1492 non-null object\n",
      "STATE                           1492 non-null object\n",
      "YEAR                            1492 non-null int64\n",
      "ENROLL                          1229 non-null float64\n",
      "TOTAL_REVENUE                   1280 non-null float64\n",
      "FEDERAL_REVENUE                 1280 non-null float64\n",
      "STATE_REVENUE                   1280 non-null float64\n",
      "LOCAL_REVENUE                   1280 non-null float64\n",
      "TOTAL_EXPENDITURE               1280 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1280 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1280 non-null float64\n",
      "OTHER_EXPENDITURE               1229 non-null float64\n",
      "CAPITAL_OUTLAY_EXPENDITURE      1280 non-null float64\n",
      "GRADES_PK_G                     1319 non-null float64\n",
      "GRADES_KG_G                     1360 non-null float64\n",
      "GRADES_4_G                      1361 non-null float64\n",
      "GRADES_8_G                      1361 non-null float64\n",
      "GRADES_12_G                     1361 non-null float64\n",
      "GRADES_1_8_G                    1361 non-null float64\n",
      "GRADES_9_12_G                   1361 non-null float64\n",
      "GRADES_ALL_G                    1319 non-null float64\n",
      "AVG_MATH_4_SCORE                536 non-null float64\n",
      "AVG_MATH_8_SCORE                532 non-null float64\n",
      "AVG_READING_4_SCORE             533 non-null float64\n",
      "AVG_READING_8_SCORE             498 non-null float64\n",
      "dtypes: float64(22), int64(1), object(2)\n",
      "memory usage: 279.8+ KB\n"
     ]
    }
   ],
   "source": [
    "education_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fractions of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                       0.000000\n",
       "STATE                             0.000000\n",
       "YEAR                              0.000000\n",
       "ENROLL                           21.399512\n",
       "TOTAL_REVENUE                    16.562500\n",
       "FEDERAL_REVENUE                  16.562500\n",
       "STATE_REVENUE                    16.562500\n",
       "LOCAL_REVENUE                    16.562500\n",
       "TOTAL_EXPENDITURE                16.562500\n",
       "INSTRUCTION_EXPENDITURE          16.562500\n",
       "SUPPORT_SERVICES_EXPENDITURE     16.562500\n",
       "OTHER_EXPENDITURE                21.399512\n",
       "CAPITAL_OUTLAY_EXPENDITURE       16.562500\n",
       "GRADES_PK_G                      13.115997\n",
       "GRADES_KG_G                       9.705882\n",
       "GRADES_4_G                        9.625276\n",
       "GRADES_8_G                        9.625276\n",
       "GRADES_12_G                       9.625276\n",
       "GRADES_1_8_G                      9.625276\n",
       "GRADES_9_12_G                     9.625276\n",
       "GRADES_ALL_G                     13.115997\n",
       "AVG_MATH_4_SCORE                178.358209\n",
       "AVG_MATH_8_SCORE                180.451128\n",
       "AVG_READING_4_SCORE             179.924953\n",
       "AVG_READING_8_SCORE             199.598394\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_df.isnull().sum()/education_df.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is no time dimension, missing data should just be filled with means on a state by state level. However, the average grade data has more null values than real values, so filling the data with mean values will be innapropriate and missing values should just be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df of States with average values for each variable\n",
    "#Create copy of df to avoid changing original data\n",
    "#Loop through education_df, if null replace with mean value for that variable for that state\n",
    "#Do not loop through the average grade data\n",
    "\n",
    "state_means = education_df.groupby('STATE').mean()\n",
    "df2 = education_df.copy(deep=True)\n",
    "\n",
    "for i in range(len(df2.columns)-4):\n",
    "    for ii in range(len(df2.iloc[:,i])):\n",
    "        if pd.isnull(df2.iloc[ii,i]):\n",
    "            df2.iloc[ii,i] = state_means.loc[df2.loc[ii, 'STATE']][i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                       0.000000\n",
       "STATE                             0.000000\n",
       "YEAR                              0.000000\n",
       "ENROLL                           12.096168\n",
       "TOTAL_REVENUE                    12.096168\n",
       "FEDERAL_REVENUE                  12.096168\n",
       "STATE_REVENUE                    12.096168\n",
       "LOCAL_REVENUE                    12.096168\n",
       "TOTAL_EXPENDITURE                12.096168\n",
       "INSTRUCTION_EXPENDITURE          12.096168\n",
       "SUPPORT_SERVICES_EXPENDITURE     12.096168\n",
       "OTHER_EXPENDITURE                 2.825637\n",
       "CAPITAL_OUTLAY_EXPENDITURE        0.268817\n",
       "GRADES_PK_G                       0.268817\n",
       "GRADES_KG_G                       0.268817\n",
       "GRADES_4_G                        0.268817\n",
       "GRADES_8_G                        0.268817\n",
       "GRADES_12_G                       0.268817\n",
       "GRADES_1_8_G                      0.674764\n",
       "GRADES_9_12_G                     1.982228\n",
       "GRADES_ALL_G                      4.189944\n",
       "AVG_MATH_4_SCORE                178.358209\n",
       "AVG_MATH_8_SCORE                180.451128\n",
       "AVG_READING_4_SCORE             179.924953\n",
       "AVG_READING_8_SCORE             199.598394\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()/df2.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This processed removed almost all of the NaN values from the grades categories, however the enrollment, revenue, and expenditure values still have ~12% missing values. Any values remaining null must be from states that never had data collected for these variables and should probably be ignored in any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMERICAN_SAMOA',\n",
       " 'AS',\n",
       " 'BI',\n",
       " 'BIE',\n",
       " 'BUREAU_OF_INDIAN_AFFAIRS',\n",
       " 'BUREAU_OF_INDIAN_EDUCATIO',\n",
       " 'BUREAU_OF_INDIAN_EDUCATION',\n",
       " 'COMMONWEALTH_OF_MARIANAS',\n",
       " 'DD',\n",
       " 'DEPARTMENT_OF_DEFENSE',\n",
       " 'DEPARTMENT_OF_DEFENSE_EDUCATION_ACTIVITY',\n",
       " 'DOD',\n",
       " 'DOD_(OVERSEAS_AND_DOMESTIC_COMBINED)',\n",
       " 'DOD_-_DOMESTIC',\n",
       " 'DOD_-_FOREIGN',\n",
       " 'DOD_-_OVERSEAS',\n",
       " 'DOD_DOMESTIC',\n",
       " 'DOD_OVERSEAS',\n",
       " 'GU',\n",
       " 'GUAM',\n",
       " 'MARIANAS',\n",
       " 'MP',\n",
       " 'NORTHERN_MARIANAS',\n",
       " 'NORTHERN_MARIANA_ISLANDS',\n",
       " 'PR',\n",
       " 'PUERTO_RICO',\n",
       " 'U.S._VIRGIN_ISLANDS',\n",
       " 'VI',\n",
       " 'VIRGIN_ISLANDS'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_states = []\n",
    "\n",
    "for i in range(len(state_means.iloc[:])):\n",
    "    for ii in range(len(state_means.iloc[i,:])):\n",
    "        if pd.isnull(state_means.iloc[i,ii]):\n",
    "            nan_states.append(state_means.index[i])\n",
    "\n",
    "set(nan_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the states who still have null values, it is clear that they are non-typical small states and the fact that data is missing from them is not surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using only the observations for that specific year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than filling in missing values by using the means of each state, I will impute them with the means for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df of Years with average values for each variable\n",
    "#Create copy of df to avoid changing original data\n",
    "#Loop through education_df, if null replace with mean value for that variable for that state\n",
    "#Do not loop through the average grade data\n",
    "\n",
    "year_means = education_df.groupby('YEAR').mean()\n",
    "df3 = education_df.copy(deep=True)\n",
    "\n",
    "for i in range(len(df3.columns)-4):\n",
    "    for ii in range(len(df3.iloc[:,i])):\n",
    "        if pd.isnull(df3.iloc[ii,i]):\n",
    "            df3.iloc[ii,i] = year_means.loc[df3.loc[ii, 'YEAR']][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                       0.000000\n",
       "STATE                             0.000000\n",
       "YEAR                              0.000000\n",
       "ENROLL                            3.539209\n",
       "TOTAL_REVENUE                     3.539209\n",
       "FEDERAL_REVENUE                   3.539209\n",
       "STATE_REVENUE                     3.539209\n",
       "LOCAL_REVENUE                     3.539209\n",
       "TOTAL_EXPENDITURE                 3.899721\n",
       "INSTRUCTION_EXPENDITURE           3.539209\n",
       "SUPPORT_SERVICES_EXPENDITURE      3.539209\n",
       "OTHER_EXPENDITURE                 3.539209\n",
       "CAPITAL_OUTLAY_EXPENDITURE        3.539209\n",
       "GRADES_PK_G                       7.338129\n",
       "GRADES_KG_G                       7.338129\n",
       "GRADES_4_G                        7.338129\n",
       "GRADES_8_G                        7.338129\n",
       "GRADES_12_G                       7.338129\n",
       "GRADES_1_8_G                      4.555011\n",
       "GRADES_9_12_G                     4.555011\n",
       "GRADES_ALL_G                      6.343550\n",
       "AVG_MATH_4_SCORE                178.358209\n",
       "AVG_MATH_8_SCORE                180.451128\n",
       "AVG_READING_4_SCORE             179.924953\n",
       "AVG_READING_8_SCORE             199.598394\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isnull().sum()/df3.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tecnique imputed much more data to the enroll, revenue, and expenditure variables. However, the grades had slightly higher null values remaining than before. Let's check which years were missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1992,\n",
       " 1993,\n",
       " 1994,\n",
       " 1995,\n",
       " 1997,\n",
       " 1998,\n",
       " 1999,\n",
       " 2001,\n",
       " 2002,\n",
       " 2004,\n",
       " 2006,\n",
       " 2008,\n",
       " 2010,\n",
       " 2012,\n",
       " 2014,\n",
       " 2016,\n",
       " 2017}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_years = []\n",
    "\n",
    "for i in range(len(year_means.iloc[:])):\n",
    "    for ii in range(len(year_means.iloc[i,:])):\n",
    "        if pd.isnull(year_means.iloc[i,ii]):\n",
    "            nan_years.append(year_means.index[i])\n",
    "\n",
    "set(nan_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. This time, fill in the missing values using interpolation (extrapolation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use interpolation on the missing average grade variables as these data were collected only during select years. I will use a linear interpolation to estimate the average grades between years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>218.410116</td>\n",
       "      <td>266.360319</td>\n",
       "      <td>212.712256</td>\n",
       "      <td>263.307067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>221.479509</td>\n",
       "      <td>270.182528</td>\n",
       "      <td>214.587049</td>\n",
       "      <td>261.412097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>224.803526</td>\n",
       "      <td>273.028605</td>\n",
       "      <td>217.612609</td>\n",
       "      <td>262.687292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>233.874626</td>\n",
       "      <td>276.743875</td>\n",
       "      <td>217.407252</td>\n",
       "      <td>262.503569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>237.053410</td>\n",
       "      <td>277.751964</td>\n",
       "      <td>218.114082</td>\n",
       "      <td>261.774971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>239.147568</td>\n",
       "      <td>280.617942</td>\n",
       "      <td>220.351554</td>\n",
       "      <td>262.154883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>239.127842</td>\n",
       "      <td>281.862386</td>\n",
       "      <td>219.799644</td>\n",
       "      <td>263.270229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>240.477019</td>\n",
       "      <td>283.490464</td>\n",
       "      <td>220.237258</td>\n",
       "      <td>264.824719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>241.891073</td>\n",
       "      <td>283.914996</td>\n",
       "      <td>221.046820</td>\n",
       "      <td>266.680635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>240.233705</td>\n",
       "      <td>281.759044</td>\n",
       "      <td>222.123041</td>\n",
       "      <td>265.007992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>239.202783</td>\n",
       "      <td>281.878993</td>\n",
       "      <td>221.095513</td>\n",
       "      <td>265.632094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "YEAR                                                            \n",
       "1992        218.410116        266.360319           212.712256   \n",
       "1993               NaN               NaN                  NaN   \n",
       "1994               NaN               NaN                  NaN   \n",
       "1995               NaN               NaN                  NaN   \n",
       "1996        221.479509        270.182528           214.587049   \n",
       "1997               NaN               NaN                  NaN   \n",
       "1998               NaN               NaN                  NaN   \n",
       "1999               NaN               NaN                  NaN   \n",
       "2000        224.803526        273.028605           217.612609   \n",
       "2001               NaN               NaN                  NaN   \n",
       "2002               NaN               NaN                  NaN   \n",
       "2003        233.874626        276.743875           217.407252   \n",
       "2004               NaN               NaN                  NaN   \n",
       "2005        237.053410        277.751964           218.114082   \n",
       "2006               NaN               NaN                  NaN   \n",
       "2007        239.147568        280.617942           220.351554   \n",
       "2008               NaN               NaN                  NaN   \n",
       "2009        239.127842        281.862386           219.799644   \n",
       "2010               NaN               NaN                  NaN   \n",
       "2011        240.477019        283.490464           220.237258   \n",
       "2012               NaN               NaN                  NaN   \n",
       "2013        241.891073        283.914996           221.046820   \n",
       "2014               NaN               NaN                  NaN   \n",
       "2015        240.233705        281.759044           222.123041   \n",
       "2016               NaN               NaN                  NaN   \n",
       "2017        239.202783        281.878993           221.095513   \n",
       "\n",
       "      AVG_READING_8_SCORE  \n",
       "YEAR                       \n",
       "1992           263.307067  \n",
       "1993                  NaN  \n",
       "1994                  NaN  \n",
       "1995                  NaN  \n",
       "1996           261.412097  \n",
       "1997                  NaN  \n",
       "1998                  NaN  \n",
       "1999                  NaN  \n",
       "2000           262.687292  \n",
       "2001                  NaN  \n",
       "2002                  NaN  \n",
       "2003           262.503569  \n",
       "2004                  NaN  \n",
       "2005           261.774971  \n",
       "2006                  NaN  \n",
       "2007           262.154883  \n",
       "2008                  NaN  \n",
       "2009           263.270229  \n",
       "2010                  NaN  \n",
       "2011           264.824719  \n",
       "2012                  NaN  \n",
       "2013           266.680635  \n",
       "2014                  NaN  \n",
       "2015           265.007992  \n",
       "2016                  NaN  \n",
       "2017           265.632094  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the state of the raw average grades data per year \n",
    "\n",
    "avg_by_year = education_df.groupby(['YEAR'])['AVG_MATH_4_SCORE', \n",
    "                               'AVG_MATH_8_SCORE', \n",
    "                               'AVG_READING_4_SCORE',\n",
    "                               'AVG_READING_8_SCORE'].mean()\n",
    "avg_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>218.410116</td>\n",
       "      <td>266.360319</td>\n",
       "      <td>212.712256</td>\n",
       "      <td>263.307067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>219.177464</td>\n",
       "      <td>267.315871</td>\n",
       "      <td>213.180954</td>\n",
       "      <td>262.833324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>219.944813</td>\n",
       "      <td>268.271424</td>\n",
       "      <td>213.649652</td>\n",
       "      <td>262.359582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>220.712161</td>\n",
       "      <td>269.226976</td>\n",
       "      <td>214.118351</td>\n",
       "      <td>261.885840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>221.479509</td>\n",
       "      <td>270.182528</td>\n",
       "      <td>214.587049</td>\n",
       "      <td>261.412097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>222.310513</td>\n",
       "      <td>270.894047</td>\n",
       "      <td>215.343439</td>\n",
       "      <td>261.730896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>223.141517</td>\n",
       "      <td>271.605566</td>\n",
       "      <td>216.099829</td>\n",
       "      <td>262.049695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>223.972521</td>\n",
       "      <td>272.317085</td>\n",
       "      <td>216.856219</td>\n",
       "      <td>262.368493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>224.803526</td>\n",
       "      <td>273.028605</td>\n",
       "      <td>217.612609</td>\n",
       "      <td>262.687292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>227.827226</td>\n",
       "      <td>274.267028</td>\n",
       "      <td>217.544157</td>\n",
       "      <td>262.626051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>230.850926</td>\n",
       "      <td>275.505452</td>\n",
       "      <td>217.475704</td>\n",
       "      <td>262.564810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>233.874626</td>\n",
       "      <td>276.743875</td>\n",
       "      <td>217.407252</td>\n",
       "      <td>262.503569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>235.464018</td>\n",
       "      <td>277.247920</td>\n",
       "      <td>217.760667</td>\n",
       "      <td>262.139270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>237.053410</td>\n",
       "      <td>277.751964</td>\n",
       "      <td>218.114082</td>\n",
       "      <td>261.774971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>238.100489</td>\n",
       "      <td>279.184953</td>\n",
       "      <td>219.232818</td>\n",
       "      <td>261.964927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>239.147568</td>\n",
       "      <td>280.617942</td>\n",
       "      <td>220.351554</td>\n",
       "      <td>262.154883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>239.137705</td>\n",
       "      <td>281.240164</td>\n",
       "      <td>220.075599</td>\n",
       "      <td>262.712556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>239.127842</td>\n",
       "      <td>281.862386</td>\n",
       "      <td>219.799644</td>\n",
       "      <td>263.270229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>239.802430</td>\n",
       "      <td>282.676425</td>\n",
       "      <td>220.018451</td>\n",
       "      <td>264.047474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>240.477019</td>\n",
       "      <td>283.490464</td>\n",
       "      <td>220.237258</td>\n",
       "      <td>264.824719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>241.184046</td>\n",
       "      <td>283.702730</td>\n",
       "      <td>220.642039</td>\n",
       "      <td>265.752677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>241.891073</td>\n",
       "      <td>283.914996</td>\n",
       "      <td>221.046820</td>\n",
       "      <td>266.680635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>241.062389</td>\n",
       "      <td>282.837020</td>\n",
       "      <td>221.584931</td>\n",
       "      <td>265.844314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>240.233705</td>\n",
       "      <td>281.759044</td>\n",
       "      <td>222.123041</td>\n",
       "      <td>265.007992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>239.718244</td>\n",
       "      <td>281.819019</td>\n",
       "      <td>221.609277</td>\n",
       "      <td>265.320043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>239.202783</td>\n",
       "      <td>281.878993</td>\n",
       "      <td>221.095513</td>\n",
       "      <td>265.632094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "YEAR                                                            \n",
       "1992        218.410116        266.360319           212.712256   \n",
       "1993        219.177464        267.315871           213.180954   \n",
       "1994        219.944813        268.271424           213.649652   \n",
       "1995        220.712161        269.226976           214.118351   \n",
       "1996        221.479509        270.182528           214.587049   \n",
       "1997        222.310513        270.894047           215.343439   \n",
       "1998        223.141517        271.605566           216.099829   \n",
       "1999        223.972521        272.317085           216.856219   \n",
       "2000        224.803526        273.028605           217.612609   \n",
       "2001        227.827226        274.267028           217.544157   \n",
       "2002        230.850926        275.505452           217.475704   \n",
       "2003        233.874626        276.743875           217.407252   \n",
       "2004        235.464018        277.247920           217.760667   \n",
       "2005        237.053410        277.751964           218.114082   \n",
       "2006        238.100489        279.184953           219.232818   \n",
       "2007        239.147568        280.617942           220.351554   \n",
       "2008        239.137705        281.240164           220.075599   \n",
       "2009        239.127842        281.862386           219.799644   \n",
       "2010        239.802430        282.676425           220.018451   \n",
       "2011        240.477019        283.490464           220.237258   \n",
       "2012        241.184046        283.702730           220.642039   \n",
       "2013        241.891073        283.914996           221.046820   \n",
       "2014        241.062389        282.837020           221.584931   \n",
       "2015        240.233705        281.759044           222.123041   \n",
       "2016        239.718244        281.819019           221.609277   \n",
       "2017        239.202783        281.878993           221.095513   \n",
       "\n",
       "      AVG_READING_8_SCORE  \n",
       "YEAR                       \n",
       "1992           263.307067  \n",
       "1993           262.833324  \n",
       "1994           262.359582  \n",
       "1995           261.885840  \n",
       "1996           261.412097  \n",
       "1997           261.730896  \n",
       "1998           262.049695  \n",
       "1999           262.368493  \n",
       "2000           262.687292  \n",
       "2001           262.626051  \n",
       "2002           262.564810  \n",
       "2003           262.503569  \n",
       "2004           262.139270  \n",
       "2005           261.774971  \n",
       "2006           261.964927  \n",
       "2007           262.154883  \n",
       "2008           262.712556  \n",
       "2009           263.270229  \n",
       "2010           264.047474  \n",
       "2011           264.824719  \n",
       "2012           265.752677  \n",
       "2013           266.680635  \n",
       "2014           265.844314  \n",
       "2015           265.007992  \n",
       "2016           265.320043  \n",
       "2017           265.632094  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_year = avg_by_year.interpolate(method='linear')\n",
    "avg_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the interpolated values need to be inserted into a copy of the original df to compare changes in nan values\n",
    "df4 = education_df.copy(deep=True)\n",
    "\n",
    "for i in range(len(df3)):\n",
    "    for ii in range(len(df3.iloc[i,-4:])):\n",
    "        if pd.isnull(df3.iloc[i,ii-4]):\n",
    "            df4.iloc[i,ii-4] = avg_by_year.loc[df4.loc[i, 'YEAR']][ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                      0.000000\n",
       "STATE                            0.000000\n",
       "YEAR                             0.000000\n",
       "ENROLL                          21.399512\n",
       "TOTAL_REVENUE                   16.562500\n",
       "FEDERAL_REVENUE                 16.562500\n",
       "STATE_REVENUE                   16.562500\n",
       "LOCAL_REVENUE                   16.562500\n",
       "TOTAL_EXPENDITURE               16.562500\n",
       "INSTRUCTION_EXPENDITURE         16.562500\n",
       "SUPPORT_SERVICES_EXPENDITURE    16.562500\n",
       "OTHER_EXPENDITURE               21.399512\n",
       "CAPITAL_OUTLAY_EXPENDITURE      16.562500\n",
       "GRADES_PK_G                     13.115997\n",
       "GRADES_KG_G                      9.705882\n",
       "GRADES_4_G                       9.625276\n",
       "GRADES_8_G                       9.625276\n",
       "GRADES_12_G                      9.625276\n",
       "GRADES_1_8_G                     9.625276\n",
       "GRADES_9_12_G                    9.625276\n",
       "GRADES_ALL_G                    13.115997\n",
       "AVG_MATH_4_SCORE                 0.000000\n",
       "AVG_MATH_8_SCORE                 0.000000\n",
       "AVG_READING_4_SCORE              0.000000\n",
       "AVG_READING_8_SCORE              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isnull().sum()/df4.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method succesfully removed all of the NaN values for the average variables. However, it may not be appropriate to impute mean variables per year to every state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare your results for the 2nd, 3rd, and 4th questions. Do you find any meaningful differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick comparison, I will plot the mean values of enroll, total revenue, grades 1_8_g, and avg math 8 score for each solution sorted by the top 5 states then years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from question 2\n",
      "                  ENROLL  TOTAL_REVENUE  GRADES_1_8_G  AVG_MATH_8_SCORE\n",
      "STATE                                                                  \n",
      "CALIFORNIA  5.933285e+06   5.484420e+07  3.845589e+06        269.355244\n",
      "TEXAS       4.277311e+06   3.601919e+07  2.785857e+06        280.455403\n",
      "NEW_YORK    2.736288e+06   4.144276e+07  1.701955e+06        278.103480\n",
      "FLORIDA     2.460021e+06   2.039945e+07  1.599173e+06        273.882398\n",
      "ILLINOIS    2.002301e+06   2.073143e+07  1.271812e+06        280.709182\n",
      "\n",
      "Output from question 3\n",
      "                  ENROLL  TOTAL_REVENUE  GRADES_1_8_G  AVG_MATH_8_SCORE\n",
      "STATE                                                                  \n",
      "CALIFORNIA  5.945343e+06    55799199.28  3.702493e+06        269.355244\n",
      "TEXAS       4.315420e+06    36879455.60  2.678940e+06        280.455403\n",
      "NEW_YORK    2.748181e+06    42385624.88  1.636678e+06        278.103480\n",
      "FLORIDA     2.486441e+06    20865131.36  1.540427e+06        273.882398\n",
      "ILLINOIS    2.026003e+06    21272992.48  1.221197e+06        280.709182\n",
      "\n",
      "Output from question 4\n",
      "                  ENROLL  TOTAL_REVENUE  GRADES_1_8_G  AVG_MATH_8_SCORE\n",
      "STATE                                                                  \n",
      "CALIFORNIA  5.945343e+06    55799199.28  3.702493e+06        273.116129\n",
      "TEXAS       4.315420e+06    36879455.60  2.678940e+06        277.812350\n",
      "NEW_YORK    2.748181e+06    42385624.88  1.636678e+06        276.817306\n",
      "FLORIDA     2.486441e+06    20865131.36  1.540427e+06        274.998625\n",
      "ILLINOIS    2.026003e+06    21272992.48  1.221197e+06        276.962968\n"
     ]
    }
   ],
   "source": [
    "print('Output from question 2')\n",
    "print(df2.groupby(['STATE'])['ENROLL', \n",
    "                        'TOTAL_REVENUE', \n",
    "                        'GRADES_1_8_G',\n",
    "                        'AVG_MATH_8_SCORE'].mean().sort_values(by='ENROLL', ascending=False)[0:5])\n",
    "print('\\nOutput from question 3')\n",
    "print(df3.groupby(['STATE'])['ENROLL', \n",
    "                        'TOTAL_REVENUE', \n",
    "                        'GRADES_1_8_G',\n",
    "                        'AVG_MATH_8_SCORE'].mean().sort_values(by='ENROLL', ascending=False)[0:5])\n",
    "print('\\nOutput from question 4')\n",
    "print(df4.groupby(['STATE'])['ENROLL', \n",
    "                        'TOTAL_REVENUE', \n",
    "                        'GRADES_1_8_G',\n",
    "                        'AVG_MATH_8_SCORE'].mean().sort_values(by='ENROLL', ascending=False)[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this quick comparison certainly does not capture the majority of the data, it gives an idea about how the different data cleaning processes affected the top 5 states. The first solution, which averaged missing values on a state level shows the greatest changes for the first 3 variables, whereas solutions 2 and 3 are identical for these variables. Solution 3 has varying average grade scroes because the values are now being averaged over the interpolated values that were imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, the best method would be to impute new values averaged over the individual states. If states are stil missing data they should be removed for that particular variable. For the average scores which are only collected every few years, values should be imputed through interpolation for each year and for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
